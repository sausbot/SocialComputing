{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import time\n",
    "import os\n",
    "\n",
    "from psaw import PushshiftAPI # to use PSAW\n",
    "\n",
    "api = PushshiftAPI()\n",
    "\n",
    "subreddits = ['Switzerland']\n",
    "start_year = 2018\n",
    "end_year = 2022\n",
    "query = \"(keyword_1)|(keyword_2)|...\" # update keywords for query here\n",
    "basecorpus = './my-dataset/' # directory to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in with agent data\n",
    "reddit = praw.Reddit(\n",
    "    user_agent=\"\",\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "### BLOCK 1 ###\n",
    "# Extract comments containing query keywords from Reddit using the Praw API\n",
    "total_comments = 0\n",
    "\n",
    "for year in range(start_year, end_year+1):\n",
    "    action = \"[Year] \" + str(year)\n",
    "    print(action)\n",
    "\n",
    "    dirpath = basecorpus + str(year)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    # timestamps that define window of posts\n",
    "    ts_after = int(dt.datetime(year, 1, 1).timestamp())\n",
    "    ts_before = int(dt.datetime(year+1, 1, 1).timestamp())\n",
    "\n",
    "    ### BLOCK 2 ###\n",
    "    for subreddit in subreddits:\n",
    "        start_time = time.time()\n",
    "\n",
    "        action = \"\\t[Subreddit] \" + subreddit\n",
    "        print(action)\n",
    "\n",
    "        subredditdirpath = dirpath + '/' + subreddit\n",
    "        if os.path.exists(subredditdirpath):\n",
    "            continue\n",
    "        else:\n",
    "            os.makedirs(subredditdirpath)\n",
    "\n",
    "        submissions_csv_path = str(year) + '-' + subreddit + '-submissions.csv'\n",
    "        \n",
    "        ### BLOCK 3 ###\n",
    "        submissions_dict = {\n",
    "            \"id\" : [],\n",
    "            \"url\" : [],\n",
    "            \"title\" : [],\n",
    "            \"score\" : [],\n",
    "            \"num_comments\": [],\n",
    "            \"created_utc\" : [],\n",
    "            \"selftext\" : [],\n",
    "            \"upvoteratio\": []\n",
    "        }\n",
    "\n",
    "        ### BLOCK 4 ###\n",
    "        # use PSAW only to get id of submissions in time interval\n",
    "        gen = api.search_submissions(\n",
    "            after=ts_after,\n",
    "            before=ts_before,\n",
    "            filter=['id'],\n",
    "            subreddit=subreddit,\n",
    "            limit=100, \n",
    "            q = query\n",
    "        )\n",
    "\n",
    "        ### BLOCK 5 ###\n",
    "        # use PRAW to get actual info and traverse comment tree\n",
    "        for submission_psaw in gen:\n",
    "            # use psaw here\n",
    "            submission_id = submission_psaw.d_['id']\n",
    "            # use praw from now on\n",
    "            submission_praw = reddit.submission(id=submission_id)\n",
    "\n",
    "            submissions_dict[\"id\"].append(submission_praw.id)\n",
    "            submissions_dict[\"url\"].append(submission_praw.url)\n",
    "            submissions_dict[\"title\"].append(submission_praw.title)\n",
    "            submissions_dict[\"score\"].append(submission_praw.score)\n",
    "            submissions_dict[\"num_comments\"].append(submission_praw.num_comments)\n",
    "            submissions_dict[\"created_utc\"].append(submission_praw.created_utc)\n",
    "            submissions_dict[\"selftext\"].append(submission_praw.selftext)\n",
    "            submissions_dict[\"upvoteratio\"].append(submission_praw.upvote_ratio)\n",
    "\n",
    "            ### BLOCK 6 ###\n",
    "            submission_comments_csv_path = str(year) + '-' + subreddit + '-submission_' + submission_id + '-comments.csv'\n",
    "            submission_comments_dict = {\n",
    "                \"comment_id\" : [],\n",
    "                \"comment_parent_id\" : [],\n",
    "                \"comment_body\" : [],\n",
    "                \"comment_link_id\" : [],\n",
    "            }\n",
    "\n",
    "            ### BLOCK 7 ###\n",
    "            # extend the comment tree all the way\n",
    "            submission_praw.comments.replace_more(limit=None)\n",
    "            # for each comment in flattened comment tree\n",
    "            for comment in submission_praw.comments.list():\n",
    "                submission_comments_dict[\"comment_id\"].append(comment.id)\n",
    "                submission_comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "                submission_comments_dict[\"comment_body\"].append(comment.body)\n",
    "                submission_comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "                total_comments += 1\n",
    "\n",
    "            # for each submission save separate csv comment file\n",
    "            pd.DataFrame(submission_comments_dict).to_csv(subredditdirpath + '/' + submission_comments_csv_path,\n",
    "                                                          index=False)\n",
    "\n",
    "        ### BLOCK 8 ###\n",
    "        # single csv file with all submissions\n",
    "        pd.DataFrame(submissions_dict).to_csv(subredditdirpath + '/' + submissions_csv_path,\n",
    "                                              index=False)\n",
    "\n",
    "        action = f\"\\t\\t[Info] Found submissions: {pd.DataFrame(submissions_dict).shape[0]}\"\n",
    "        print(action)\n",
    "\n",
    "        action = f\"\\t\\t[Info] Elapsed time: {time.time() - start_time: .2f}s\"\n",
    "        print(action)\n",
    "\n",
    "print(total_comments)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
